# CH.06 데이터 압축
- MySQL 서버에서 디스크에 저장된 데이터 파일의 크기는 일반적으로 쿼리의 처리성능과도 직결되지만 백업 및 복구 시간과도 밀접하게 연결된다.
- 디스크의 데이터 파일이 크면 클수록 쿼리를 처리하기 위해서 더 많은 데이터 페이지를 InnoDB 버퍼풀로 읽어야 할 수도 있고, 새로운 페이지가 버퍼풀로 적재되기 때문에 그만큼 더티 페이지가 더 자주 디스크로 기록돼야 한다.
- 그리고 데이터 파일이 크면 클수록 백업시간이 오래 걸리며, 복구하는 데도 그만큼의 시간이 걸린다.
## 6.1 페이지 압축
- MySQL 서버가 디스크에 저장하는 시점에 데이터 페이지가 압축되어 저장되고, 반대로 MySQL 서버가 디스크에서 데이터 페이지를 읽어올 때 압축이 해제된다.
- 16KB 데이터 페이지를 압축한 결과가 용량이 얼마나 될지 예측이 불가능한데 적어도 하나의 테이블은 동일한 크기의 페이지(블록)로 통일돼야 한다.
- 페이지 압축 기능은 운영체제별로 특정 버전의 파일 시스템에서만 지원되는 펀치 홀(Punch hole)이라는 기능을 사용한다.
- 운영체제(파일 시스템)의 블록 사이즈가 512바이트인 경우, 페이지 압축이 작동하는 방식
```text
1. 16KB 페이지를 압축(압축 결과를 7KB로 가정)
2. MySQL 서버는 디스크에 압축된 결과 7KB를 기록 (이때 MySQL 서버는 압축 데이터 7KB에 9KB의 빈 데이터를 기록)
3. 디스크에 데이터를 기록한 후, TKB 이후의 공간 9KB에 대해 펀치 홀(Punch-hole)을 생성
4. 파일 시스템은 7B만 남기고 나머지 디스크의 9KB 공간은 다시 운영체제로 반납
```
- MySQL 서버의 페이지 압축이 가진 문제는 펀치 홀 기능은 운영체제뿐만 아니라 하드웨어 자체에서도 해당기능을 지원해야 사용 가능하다는 점이다.
- 또다른 문제점은 아직 파일 시스템 관련 명령어(유틸리티)가 펀치 홀을 지원하지 못하다는 것이다.
- MySQL 서버의 데이터 파일은 해당 서버에만 머무는 것이 아니라 백업했다가 복구하는 과정에서 데이터 파일 복사 과정이 실행되고, 그 외에도 많은 파일 관련 유틸리티들을 사용한다.
- 이런 이유로 실제 페이지 압축은 많이 사용되지 않는 상태다.
## 6.2 테이블 압축
- 테이블 압축은 운영체제나 하드웨어에 대한 제약없이 사용할 수 있기 때문에 일반적으로 더 활용도가 높은 편이다.
- 테이블 압축 단점
  - 버퍼 풀 공간 활용률이 낮음
  - 쿼리 처리 성능이 낮음
  - 빈번한 데이터 변경 시 압축률이 떨어짐
### 6.2.1 압축 테이블 생성
- KEY_BLOCK_SIZE 옵션을 이용해 압축된 페이지의 타깃 크기(목표 크기)를 명시하는데, 2n(n 값은 2 이상)으로만 설정할 수 있다.
- InnoDB 스토리지 엔진의 페이지 크기(innodb_page_size)가 16KB라면 KEY_BLOCK_SIZE는 4KB 또는 8KB만 설정할 수 있다.
- 그리고 페이지 크기가 32KB 또는 64KB인 경우에는 테이블 압축을 적용할 수 없다.
- 현재 InnoDB 스토리지 엔진의 데이터 페이지(블록) 크기가 16KB, 그리고 KEY_BLOCK_SIZE가 8로 설정됐다고 가정해보자. 데이터 페이지를 압축한 용량이 얼마가 될지 알 수 없는데, 어떻게 KEY_BLOCK_SIZE를 테이블을 생성할 때 설정할 수 있을까?
```text
1. 16KB의 데이터 페이지를 압축
    1.1 압축된 결과가 8KB 이하이면 그대로 디스크에 저장(압축 완료)
    1.2 압축된 결과가 8KB를 초과하면 원본 페이지를 스플릿(split)해서 2개의 페이지에 8KB씩 저장
2. 나뉜 페이지 각각에 대해 1*번 단계를 반복 실행
```
- 테이블 압축 방식에서 가장 중요한 것은 원본 데이터 페이지의 압축결과가 목표 크기(KEY_BLOCK SIZE) 보다 작거나 같을 때까지 반복해서 페이지를 스플릿하는 것이다.
- 그래서 목표 크기가 잘못 설정되면 MySQL 서버의 처리 성능이 급격히 떨어질 수 있으니 주의하자.
### 6.2.2 KEY_BLOCK_SIZE 결정
- 테이블 압축을 적용하기 전에 먼저 KEY_BLOCK_SIZE를 4KB 또는 8KB로 테이블을 생성해서 샘플 데이터를 저장해보고 적절한지 판단하는 것이 좋다.
- 최소한 테이블의 데이터 페이지가 10개 정도는 생성되도록 테스트 데이터를 INSERT해보는 것이 좋다.
```text
mysql> USE employees;

-- // employees 테이블과 동일한 구조로, 테이블 압축을 사용하는 예제 테이블을 생성
mysql> CREATE TABLE employees_comp4k (
    emp_no int NOT NULL,
    birth_date date NOT NULL,
    first_name varchar(14) NOT NULL,
    last_name varchar(16) NOT NULL,
    gender enum('M','F') NOT NULL,
    hire_date date NOT NULL,
    PRIMARY KEY (emp_no),
    KEY ix_firstname (first_name),
    KEY ix_hiredate (hire_date)
) ROW_FORMAT=COMPRESSED KEY_BLOCK_SIZE=4;

-- // 데스트를 실행하기 전에 innodb_cmp_per_index_enabled 시스템 변수를 ON으로 변경해야
-- // 인덱스로 압축 실행 횟수와 성공 횟수가 기록된다.
mysql> SET GLOBAL innodb_cmp_per_index_enabled=ON;

-- // employees 테이블의 데이터를 그대로 압축 테스트 테이블로 저장
mysql> INSERT INTO employees_comp4k SELECT * FROM employees;

-- // 인덱스로 압축 횟수와 성공 횟수, 압축 실패율을 조회
mysql> SELECT
    table_name, index_name, compress_ops, compress_ops_ok,
    (compress_ops-compress_ops_ok)/compress_ops * 100 as compression_failure_pct
FROM information_schema.INNODB_CMP_PER_INDEX;

+------------------+--------------+--------------+-----------------+-------------------------+
| table_name       | index_name   | compress_ops | compress_ops_ok | compression_failure_pct |
+------------------+--------------+--------------+-----------------+-------------------------+
| employees_comp4k | PRIMARY      |        18635 |           13478 |                 27.6737 |
| employees_comp4k | ix_firstname |         8320 |            7853 |                  8.0168 |
| employees_comp4k | ix_hiredate  |         7786 |            6721 |                 13.4561 |
+------------------+--------------+--------------+-----------------+-------------------------+
```
- 압축된 테이블의 PRIMARY 키는 전체 18653번 압축을 실행했는데, 그 중에서 13478번 성공했다.
- 즉 5175(18653 - 13478)번 압축했는데, 압축의 결과가 4KB를 초과해서 데이터 페이지를 스플릿해서 다시 압축을 실행했다는 의미다.
- 일반적으로 압축 실패율은 3~5% 미만으로 유지할 수 있게 KEY_BLOCK_SIZE를 선택하는 것이 좋다.
- KEY_BLOCK SIZE를 8KB로 설정 테스트
```text
mysql> SELECT
    table_name, index_name, compress_ops, compress_ops_ok,
    (compress_ops-compress_ops_ok)/compress_ops * 100 as compression_failure_pct
FROM information_schema.INNODB_CMP_PER_INDEX;

+------------------+--------------+--------------+-----------------+-------------------------+
| table_name       | index_name   | compress_ops | compress_ops_ok | compression_failure_pct |
+------------------+--------------+--------------+-----------------+-------------------------+
| employees_comp8k | PRIMARY      |         8892 |            6593 |                 18.5245 |
| employees_comp8k | ix_firstname |         1996 |            1996 |                  0.0000 |
| employees_comp8k | ix_hiredate  |         1391 |            1381 |                  0.7189 |
+------------------+--------------+--------------+-----------------+-------------------------+
```
- KEY_BLOCK_SIZE를 8KB로 설정했음에도 불구하고 PRIMARY 키의 압축 실패율이 꽤 높게 나타난 것을 알 수 있다.
- 성능에 민감한 서비스라면 employees 테이블은 압축을 적용하지 않는것이 좋다고 판단할 수 있다.
- 4KB 압축과 8KB 압축의 결과가 거의 차이나지 않는다.
- 이 경우 굳이 압축을 선택해야 한다면 압축 실패율은 낮으면서 압축 효율은 상대적으로 높은 8KB를 선택하는 것이 훨씬 효율적일 것이다.
- 압축 실패율이 높다고 해서 압축을 사용하지 말아야 한다는 것을 의미하지는 않는다는 것이다.
- INSERT만 되는 로그 테이블의 경우에는 한 번 INSERT 되면 이후 다시는 변경되지 않을 것이다.
- 그렇다면 한 번 정도는 압축 시도가 실패해서 페이지 스플릿 후 재압축 한다고 하더라도 전체적으로 데이터 파일의 크기가 큰 폭으로 줄어든다면 큰 손해는 아닐 것이다.
- 압축 실패율이 그다지 높지 않은 경우라고 하더라도 테이블의 데이터가 매우 빈번하게 조회되고 변경된다면 압축은 고려하지 않는 것이 좋다.
### 6.2.3 압축된 페이지의 버퍼 풀 적재 및 사용
- InnoDB 스토리지 엔진은 압축된 테이블의 데이터 페이지를 버퍼풀에 적재하면 압축된 상태와 압축이 해제된 상태 2개 버전을 관리한다.
- InnoDB 스토리지 엔진은 디스크에서 읽은 상태 그대로의 데이터 페이지 목록을 관리하는 LRU 리스트와 압축된 페이지들의 압축 해제 버전인 Unzip_LRU 리스트를 별도로 관리하게 된다.
- InnoDB 스토리지 엔진은 압축된 테이블에 대해서는 버퍼 풀의 공간을 이중으로 사용함으로써 메모리를 낭비하는 효과를 가진다.
- 또다른 문제점으로는 압축된 페이지에서 데이터를 읽거나 변경하기 위해서는 압축을 해제해야 한다는 것인데, 압축 및 압축 해제 작업은 CPU를 상대적으로 많이 소모하는 작업이다.
- 이러한 두 가지 단점을 보완하기 위해 Unzip_LRU 리스트를 별도로 관리하고 있다가 MySQL 서버로 유입되는 요청 패턴에 따라서 적절히(Adaptive) 다음과 같은 처리를 수행한다.
### 6.2.4 테이블 압축 관련 설정
- InnoDB 버퍼 풀의 공간이 필요한 경우에는 LRU 리스트에서 원본 데이터 페이지(압축된 형태)는 유지하고, Unzip_ LRU 리스트에서 압축 해제된 버전은 제거해서 버퍼 풀의 공간을 확보한다.
- 압축된 데이터 페이지가 자주 사용되는 경우에는 Unzip_LRU 리스트에 압축 해제된 페이지를 계속 유지하면서 압축 및 압축 해제 작업을 최소화한다.
- 압축된 데이터 페이지가 사용되지 않아서 LRU 리스트에서 제거되는 경우에는 Unzip_LRU 리스트에서도 함께 제거된다.
- 버퍼 풀에서 압축 해제된 버전의 데이터 페이지를 적절한 수준으로 유지하기 위해 어댑티브(적응적인) 알고리즘을 사용
  - CPU 사용량이 높은 서버에서는 가능하면 압축과 압축 해제를 피하기 위해 Unzip_LRU의 비율을 높여서 유지하고
  - Disk IO 사용량이 높은 서버에서는 가능하면 Unzip_LRU 리스트의 비율을 낮춰서 InnoDB 버퍼 풀의 공간을 더 확보하도록 작동한다.